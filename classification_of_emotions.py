# -*- coding: utf-8 -*-
"""Classification of Emotions.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KOzwAExLZj8shbTkIJ09NqGrkNEmR_Ni

## **Libraries**
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import zipfile
from google.colab.patches import cv2_imshow
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Flatten, BatchNormalization

from google.colab import drive
drive.mount('/content/drive')

path='/content/drive/MyDrive/Computer Vision Masterclass/Datasets/fer_images.zip'
zip_object=zipfile.ZipFile(file=path,mode='r')
zip_object.extractall('./')
zip_object.close()

tf.keras.preprocessing.image.load_img('/content/fer2013/train/Angry/1000.jpg')

from pickle import load
image= tf.keras.preprocessing.image.load_img('/content/fer2013/train/Fear/1003.jpg')
image

"""## **Train and Test set**"""

train_datagen= ImageDataGenerator(rescale=1./255,
                                   rotation_range=8,
                                   horizontal_flip=True,
                                   zoom_range=0.2)

train_dataset = train_datagen.flow_from_directory('/content/fer2013/train',
                                                  target_size=(48,48),
                                                  batch_size=16,
                                                  class_mode='categorical',
                                                  shuffle=True)

train_dataset.class_indices

np.unique(train_dataset.classes, return_counts= True)

sns.countplot(x=train_dataset.classes)

test_datagen= ImageDataGenerator(rescale=1./255)

test_dataset = test_datagen.flow_from_directory('/content/fer2013/validation',
                                                  target_size=(48,48),
                                                  batch_size=16,
                                                  class_mode='categorical',
                                                  shuffle=False)

"""## **Building and training CNN**"""

num_detector = 32
num_classes = 7
width , height = 48, 48
epochs = 90

network = Sequential()

network.add(Conv2D(num_detector, (3,3), activation='relu',padding ='same', input_shape=(width, height, 3)))
network.add(BatchNormalization())
network.add(Conv2D(num_detector, (3,3), activation='relu',padding ='same'))
network.add(BatchNormalization())
network.add(MaxPooling2D(pool_size=(2,2)))
network.add(Dropout(0.2))

network.add(Conv2D(2*num_detector, (3,3), activation='relu',padding ='same'))
network.add(BatchNormalization())
network.add(Conv2D(2*num_detector, (3,3), activation='relu',padding ='same'))
network.add(BatchNormalization())
network.add(MaxPooling2D(pool_size=(2,2)))
network.add(Dropout(0.2))

network.add(Conv2D(2*2*num_detector, (3,3), activation='relu',padding ='same'))
network.add(BatchNormalization())
network.add(Conv2D(2*2*num_detector, (3,3), activation='relu',padding ='same'))
network.add(BatchNormalization())
network.add(MaxPooling2D(pool_size=(2,2)))
network.add(Dropout(0.2))

network.add(Conv2D(2*2*2*num_detector, (3,3), activation='relu',padding ='same'))
network.add(BatchNormalization())
network.add(Conv2D(2*2*2*num_detector, (3,3), activation='relu',padding ='same'))
network.add(BatchNormalization())
network.add(MaxPooling2D(pool_size=(2,2)))
network.add(Dropout(0.2))

network.add(Flatten())

network.add(Dense(2*num_detector, activation='relu'))
network.add(BatchNormalization())
network.add(Dropout(0.2))

network.add(Dense(2*num_detector, activation='relu'))
network.add(BatchNormalization())
network.add(Dropout(0.2))

network.add(Dense(num_classes, activation='softmax'))

print(network.summary())

network.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

network.fit(train_dataset, epochs=80)



"""# **Saving Model**"""

model_json = network.to_json()
with open("emotion_model.json", "w") as json_file:
    json_file.write(model_json)

from keras.models import save_model
Network_saved = save_model(network, 'Network_emotion_weights.hdf5')

with open('/content/emotion_model.json') as json_file:
  json_file_loaded = json_file.read()
json_file_loaded

network_loaded= tf.keras.models.model_from_json(json_file_loaded)
network_loaded.load_weights('Network_emotion_weights.hdf5')
network_loaded.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

network_loaded.summary()

"""## **Evaluation of Model**"""

network_loaded.evaluate(test_dataset)

predict= network_loaded.predict(test_dataset)
predict

predict =np.argmax(predict, axis=1)
predict

test_dataset.classes

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(test_dataset.classes, predict)
cm

from sklearn.metrics import accuracy_score
accuracy_score(test_dataset.classes, predict)

test_dataset.class_indices

sns.heatmap(cm, annot=True, cmap='Blues', fmt='d')

"""## **Classifying one image**"""

image= cv2.imread('/content/drive/MyDrive/Colab Notebooks/Emeka.3.2.png')
cv2_imshow(image)

face_detector=cv2.CascadeClassifier('/content/drive/MyDrive/Computer Vision Masterclass/Cascades/haarcascade_frontalface_default.xml')

original_image = image.copy()
faces = face_detector.detectMultiScale(original_image, scaleFactor=1.2, minNeighbors=5,minSize=(30,30))

roi=image[40:40 + 128, 162:162 + 128]
cv2_imshow(roi)

roi = cv2.resize(roi, (48,48))
cv2_imshow(roi)

roi=roi/255

roi=np.expand_dims(roi, axis=0)

probs=network_loaded.predict(roi)
probs

results=np.argmax(probs)
results

test_dataset.class_indices

"""## **Classifying mutiple Images**"""

image=cv2.imread('/content/drive/MyDrive/Computer Vision Masterclass/Images/faces_emotions.png')
cv2_imshow(image)

faces=face_detector.detectMultiScale(image, scaleFactor=1.2, minNeighbors=5,minSize=(30,30))

test_dataset.class_indices.keys()

emotions=['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']

for (x,y,w,h) in faces:
  cv2.rectangle(image, (x,y), (x+w, y+h), (0,255,0),1)
  roi=image[y:y+h, x:x+w]
  #cv2_imshow(roi)
  roi = cv2.resize(roi, (48,48))
  roi=roi/255
  roi=np.expand_dims(roi, axis=0)
  predict=network_loaded.predict(roi)
  cv2.putText(image, emotions[np.argmax(predict)], (x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),1,cv2.LINE_AA)
  result=np.argmax(predict)
cv2_imshow(image)

"""# Classifying of emotion in video"""

cap = cv2.VideoCapture('/content/drive/MyDrive/Computer Vision Masterclass/Videos/emotion_test01.mp4')
connected, video = cap.read()
print(connected, video.shape)

save_path = '/content/drive/MyDrive/Computer Vision Masterclass/Videos/emotion_test01_result.avi'
fourcc = cv2.VideoWriter_fourcc(*'XVID')
fps = 22 # frame per second
output_video = cv2.VideoWriter(save_path, fourcc, fps, (video.shape[1], video.shape[0]))

while(cv2.waitKey(1) < 0):
  connected, frame = cap.read()
  if not connected:
    break
    faces = face_detector.detectMultiScale(frame, scaleFactor=1.2, minNeighbors=5,minSize=(30,30))
    if len(faces) > 0:
      for (x,y,w,h) in faces:
       frame=cv2.rectangle(frame, (x,y), (x+w, y+h), (0,255,0), 2)
       roi =frame[y:y+h, x:x+w]
       roi = cv2.resize(roi, (48,48))
       roi = roi/255
       roi = np.expand_dims(roi, axis=0)
       prediction= network_load.predict(roi)

       if prediction is not None:
         result = np.argmax(prediction)
         cv2.putText(frame,emotion[result], (x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),1,cv2.LINE_AA )

  cv2_imshow(frame)